{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.kernel_based import TimeSeriesSVC, RocketClassifier, TimeSeriesSVCTslearn\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "combined = pd.read_csv(\"/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/combined.csv\",index_col=['Primary_Index','ref_date'])\n",
    "# combined = pd.read_csv(\"/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127694, 172)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_columns = ['threshold_date', 'diagnosis_date', 'date_of_birth', 'date_of_death',\n",
    "\t'Practice', 'PatientID',\n",
    "\t'systolic', 'diastolic', 'weight', 'height', 'age_group',\n",
    "\t'race','vitals_id', 'mean_arterial_pressure', 'age', 'bsa', 'pulse', 'time_in_days']\n",
    "df_filtered = combined.drop(columns=exclude_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify groups with only one entry\n",
    "group_sizes = df_filtered.groupby(level='Primary_Index').size()\n",
    "\n",
    "#Filter out groups with greater than 10 entries\n",
    "indices_to_keep = group_sizes[group_sizes > 10].index\n",
    "df_filtered = df_filtered.loc[indices_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(df_filtered.index.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.sort_index(level=1, ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered.groupby(level='Primary_Index').head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'ref_date' index to datetime if it's not already\n",
    "if not pd.api.types.is_datetime64_any_dtype(df_filtered.index.get_level_values('ref_date')):\n",
    "    # Create a new MultiIndex with the 'ref_date' converted to datetime\n",
    "    df_filtered.index = pd.MultiIndex.from_arrays([\n",
    "        df_filtered.index.get_level_values('Primary_Index'),\n",
    "        pd.to_datetime(df_filtered.index.get_level_values('ref_date'))\n",
    "    ], names=['Primary_Index', 'ref_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to assign integer values based on order\n",
    "def convert_secondary_index_to_int(df):\n",
    "    df = df.copy()\n",
    "    df['Secondary_Index_Int'] = df.groupby(level=0).cumcount()\n",
    "    return df.set_index('Secondary_Index_Int', append=True).reset_index(level=1, drop=True)\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "df_filtered = convert_secondary_index_to_int(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ethnicity_mapping</th>\n",
       "      <th>gender</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>race_mapping</th>\n",
       "      <th>bmi</th>\n",
       "      <th>respiration</th>\n",
       "      <th>temperature</th>\n",
       "      <th>bmi_group</th>\n",
       "      <th>bsa_group</th>\n",
       "      <th>map_group</th>\n",
       "      <th>...</th>\n",
       "      <th>hepatitis_c</th>\n",
       "      <th>thyroid_gland_disorders</th>\n",
       "      <th>rheumatoid_arthritis</th>\n",
       "      <th>osteoarthritis</th>\n",
       "      <th>gerd</th>\n",
       "      <th>neurological_disorders</th>\n",
       "      <th>chronic_lung_disease</th>\n",
       "      <th>depression</th>\n",
       "      <th>hypercholesterolemia</th>\n",
       "      <th>is_diagnosed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary_Index</th>\n",
       "      <th>Secondary_Index_Int</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8595</th>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10073</th>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.81</td>\n",
       "      <td>16.0</td>\n",
       "      <td>97.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9507</th>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>96.900002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8595</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17174</th>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4615</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1135</th>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10707</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6246 rows Ã— 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   ethnicity_mapping  gender  marital_status  \\\n",
       "Primary_Index Secondary_Index_Int                                              \n",
       "8595          0                                  0.0     1.0             1.0   \n",
       "10073         0                                  0.0     0.0             1.0   \n",
       "9507          0                                  0.0     1.0             0.0   \n",
       "8595          1                                  0.0     1.0             1.0   \n",
       "17174         0                                  0.0     1.0             0.0   \n",
       "...                                              ...     ...             ...   \n",
       "2093          1                                  0.0     1.0             1.0   \n",
       "4615          1                                  0.0     1.0             1.0   \n",
       "1135          0                                  1.0     1.0             1.0   \n",
       "              1                                  1.0     1.0             1.0   \n",
       "10707         1                                  0.0     1.0             1.0   \n",
       "\n",
       "                                   race_mapping    bmi  respiration  \\\n",
       "Primary_Index Secondary_Index_Int                                     \n",
       "8595          0                             0.0  31.32          0.0   \n",
       "10073         0                             0.0  26.81         16.0   \n",
       "9507          0                             0.0   0.00         18.0   \n",
       "8595          1                             0.0  31.32          0.0   \n",
       "17174         0                             0.0   0.00         12.0   \n",
       "...                                         ...    ...          ...   \n",
       "2093          1                             1.0   0.00          0.0   \n",
       "4615          1                             1.0   0.00         16.0   \n",
       "1135          0                             1.0   0.00         18.0   \n",
       "              1                             1.0   0.00         18.0   \n",
       "10707         1                             0.0   0.00          0.0   \n",
       "\n",
       "                                   temperature  bmi_group  bsa_group  \\\n",
       "Primary_Index Secondary_Index_Int                                      \n",
       "8595          0                       0.000000        4.0        4.0   \n",
       "10073         0                      97.500000        3.0        3.0   \n",
       "9507          0                      96.900002        0.0        0.0   \n",
       "8595          1                       0.000000        4.0        4.0   \n",
       "17174         0                       0.000000        0.0        0.0   \n",
       "...                                        ...        ...        ...   \n",
       "2093          1                       0.000000        0.0        0.0   \n",
       "4615          1                      98.000000        0.0        0.0   \n",
       "1135          0                      99.000000        0.0        0.0   \n",
       "              1                      99.000000        0.0        0.0   \n",
       "10707         1                       0.000000        0.0        0.0   \n",
       "\n",
       "                                   map_group  ...  hepatitis_c  \\\n",
       "Primary_Index Secondary_Index_Int             ...                \n",
       "8595          0                          0.0  ...          0.0   \n",
       "10073         0                          2.0  ...          0.0   \n",
       "9507          0                          2.0  ...          0.0   \n",
       "8595          1                          0.0  ...          0.0   \n",
       "17174         0                          4.0  ...          0.0   \n",
       "...                                      ...  ...          ...   \n",
       "2093          1                          2.0  ...          0.0   \n",
       "4615          1                          2.0  ...          0.0   \n",
       "1135          0                          4.0  ...          0.0   \n",
       "              1                          4.0  ...          0.0   \n",
       "10707         1                          2.0  ...          0.0   \n",
       "\n",
       "                                   thyroid_gland_disorders  \\\n",
       "Primary_Index Secondary_Index_Int                            \n",
       "8595          0                                        0.0   \n",
       "10073         0                                        0.0   \n",
       "9507          0                                        0.0   \n",
       "8595          1                                        0.0   \n",
       "17174         0                                        0.0   \n",
       "...                                                    ...   \n",
       "2093          1                                        0.0   \n",
       "4615          1                                        0.0   \n",
       "1135          0                                        0.0   \n",
       "              1                                        0.0   \n",
       "10707         1                                        0.0   \n",
       "\n",
       "                                   rheumatoid_arthritis  osteoarthritis  gerd  \\\n",
       "Primary_Index Secondary_Index_Int                                               \n",
       "8595          0                                     0.0             0.0   0.0   \n",
       "10073         0                                     0.0             1.0   0.0   \n",
       "9507          0                                     0.0             0.0   0.0   \n",
       "8595          1                                     0.0             0.0   0.0   \n",
       "17174         0                                     0.0             0.0   0.0   \n",
       "...                                                 ...             ...   ...   \n",
       "2093          1                                     0.0             0.0   0.0   \n",
       "4615          1                                     0.0             1.0   0.0   \n",
       "1135          0                                     1.0             1.0   0.0   \n",
       "              1                                     1.0             1.0   0.0   \n",
       "10707         1                                     0.0             0.0   0.0   \n",
       "\n",
       "                                   neurological_disorders  \\\n",
       "Primary_Index Secondary_Index_Int                           \n",
       "8595          0                                       1.0   \n",
       "10073         0                                       0.0   \n",
       "9507          0                                       0.0   \n",
       "8595          1                                       1.0   \n",
       "17174         0                                       0.0   \n",
       "...                                                   ...   \n",
       "2093          1                                       0.0   \n",
       "4615          1                                       0.0   \n",
       "1135          0                                       0.0   \n",
       "              1                                       0.0   \n",
       "10707         1                                       0.0   \n",
       "\n",
       "                                   chronic_lung_disease  depression  \\\n",
       "Primary_Index Secondary_Index_Int                                     \n",
       "8595          0                                     1.0         0.0   \n",
       "10073         0                                     0.0         0.0   \n",
       "9507          0                                     0.0         0.0   \n",
       "8595          1                                     1.0         0.0   \n",
       "17174         0                                     0.0         0.0   \n",
       "...                                                 ...         ...   \n",
       "2093          1                                     0.0         0.0   \n",
       "4615          1                                     0.0         0.0   \n",
       "1135          0                                     1.0         0.0   \n",
       "              1                                     1.0         0.0   \n",
       "10707         1                                     0.0         0.0   \n",
       "\n",
       "                                   hypercholesterolemia  is_diagnosed  \n",
       "Primary_Index Secondary_Index_Int                                      \n",
       "8595          0                                     1.0             1  \n",
       "10073         0                                     1.0             1  \n",
       "9507          0                                     0.0             1  \n",
       "8595          1                                     1.0             1  \n",
       "17174         0                                     1.0             1  \n",
       "...                                                 ...           ...  \n",
       "2093          1                                     0.0             1  \n",
       "4615          1                                     1.0             1  \n",
       "1135          0                                     1.0             1  \n",
       "              1                                     1.0             1  \n",
       "10707         1                                     0.0             1  \n",
       "\n",
       "[6246 rows x 154 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set second index to datetime\n",
    "df_filtered.index = df_filtered.index.set_levels([df_filtered.index.levels[0], pd.to_datetime(df_filtered.index.levels[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is in the correct format for sktime.\n"
     ]
    }
   ],
   "source": [
    "from sktime.datatypes import check_raise\n",
    "\n",
    "# Assuming df_filtered is your DataFrame with a possible MultiIndex structure\n",
    "try:\n",
    "    # Check if the DataFrame is in the correct 'pd-multiindex' format expected by sktime\n",
    "    check_raise(df_filtered, mtype=\"pd-multiindex\")\n",
    "    print(\"Data is in the correct format for sktime.\")\n",
    "except Exception as e:\n",
    "    # Handle the exception if the format is not correct\n",
    "    print(f\"Data format error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_filtered[[x for x in df_filtered.columns if x!='is_diagnosed']]\n",
    "y = df_filtered['is_diagnosed'][::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 3123 elements, new values have 6246 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mindex\n",
      "File \u001b[0;32m/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/myenv/lib/python3.8/site-packages/pandas/core/generic.py:6002\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6000\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   6001\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[0;32m-> 6002\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6003\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   6004\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/myenv/lib/python3.8/site-packages/pandas/_libs/properties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/myenv/lib/python3.8/site-packages/pandas/core/generic.py:730\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    729\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/myenv/lib/python3.8/site-packages/pandas/core/internals/managers.py:225\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[0;32m/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/myenv/lib/python3.8/site-packages/pandas/core/internals/base.py:70\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 3123 elements, new values have 6246 elements"
     ]
    }
   ],
   "source": [
    "y.index = X.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [DatetimeIndex(['1970-01-01 00:00:00.000000001'], dtype='datetime64[ns]', name='Secondary_Index_Int', freq=None)] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X\u001b[38;5;241m.\u001b[39mloc[train_indices], X\u001b[38;5;241m.\u001b[39mloc[test_indices], y\u001b[38;5;241m.\u001b[39mloc[train_indices], y\u001b[38;5;241m.\u001b[39mloc[test_indices]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Apply the group_train_test_split function\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mgroup_train_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 11\u001b[0m, in \u001b[0;36mgroup_train_test_split\u001b[0;34m(X, y, test_size)\u001b[0m\n\u001b[1;32m      9\u001b[0m X_group \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mloc[group]\n\u001b[1;32m     10\u001b[0m y_group \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mloc[group]\n\u001b[0;32m---> 11\u001b[0m X_train_group, X_test_group, y_train_group, y_test_group \u001b[38;5;241m=\u001b[39m \u001b[43mtemporal_train_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m train_indices\u001b[38;5;241m.\u001b[39mextend(X_train_group\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m     14\u001b[0m test_indices\u001b[38;5;241m.\u001b[39mextend(X_test_group\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtolist())\n",
      "File \u001b[0;32m/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/myenv/lib/python3.8/site-packages/sktime/forecasting/model_selection/__init__.py:43\u001b[0m, in \u001b[0;36mtemporal_train_test_split\u001b[0;34m(y, X, test_size, train_size, fh, anchor)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msplit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m temporal_train_test_split \u001b[38;5;28;01mas\u001b[39;00m _tts\n\u001b[1;32m     34\u001b[0m warn(\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWARNING - the old location of temporal_train_test_split in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msktime.forecasting.model_selection is deprecated and is scheduled for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m     41\u001b[0m )\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manchor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manchor\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/myenv/lib/python3.8/site-packages/sktime/split/temporal_train_test_split.py:144\u001b[0m, in \u001b[0;36mtemporal_train_test_split\u001b[0;34m(y, X, test_size, train_size, fh, anchor)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msplit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SameLocSplitter\n\u001b[1;32m    143\u001b[0m X_splitter \u001b[38;5;241m=\u001b[39m SameLocSplitter(temporal_splitter, y)\n\u001b[0;32m--> 144\u001b[0m X_train, X_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_splitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_train, y_test, X_train, X_test\n",
      "File \u001b[0;32m/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/myenv/lib/python3.8/site-packages/sktime/split/base/_base_splitter.py:286\u001b[0m, in \u001b[0;36mBaseSplitter.split_series\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m _split(y_inner\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m    285\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m _slicer[train]\n\u001b[0;32m--> 286\u001b[0m     y_test \u001b[38;5;241m=\u001b[39m \u001b[43m_slicer\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    288\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m convert(y_train, from_type\u001b[38;5;241m=\u001b[39my_inner_mtype, to_type\u001b[38;5;241m=\u001b[39my_orig_mtype)\n\u001b[1;32m    289\u001b[0m     y_test \u001b[38;5;241m=\u001b[39m convert(y_test, from_type\u001b[38;5;241m=\u001b[39my_inner_mtype, to_type\u001b[38;5;241m=\u001b[39my_orig_mtype)\n",
      "File \u001b[0;32m/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/myenv/lib/python3.8/site-packages/pandas/core/indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1100\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1102\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/myenv/lib/python3.8/site-packages/pandas/core/indexing.py:1332\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1330\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/myenv/lib/python3.8/site-packages/pandas/core/indexing.py:1272\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1272\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1274\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m )\n",
      "File \u001b[0;32m/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/myenv/lib/python3.8/site-packages/pandas/core/indexing.py:1462\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1459\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1460\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1462\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/myenv/lib/python3.8/site-packages/pandas/core/indexes/base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5877\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/myenv/lib/python3.8/site-packages/pandas/core/indexes/base.py:5938\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5936\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   5937\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [DatetimeIndex(['1970-01-01 00:00:00.000000001'], dtype='datetime64[ns]', name='Secondary_Index_Int', freq=None)] are in the [index]\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sktime.split import TemporalTrainTestSplitter\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "def group_train_test_split(X, y, test_size=0.2):\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    \n",
    "    for group in X.index.get_level_values('Primary_Index').unique():\n",
    "        X_group = X.loc[group]\n",
    "        y_group = y.loc[group]\n",
    "        X_train_group, X_test_group, y_train_group, y_test_group = temporal_train_test_split(X_group, y_group, test_size=test_size)\n",
    "        \n",
    "        train_indices.extend(X_train_group.index.tolist())\n",
    "        test_indices.extend(X_test_group.index.tolist())\n",
    "    \n",
    "    return X.loc[train_indices], X.loc[test_indices], y.loc[train_indices], y.loc[test_indices]\n",
    "\n",
    "# Apply the group_train_test_split function\n",
    "X_train, X_test, y_train, y_test = group_train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Lengths must match to compare",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\n",
      "File \u001b[0;32m/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/myenv/lib/python3.8/site-packages/pandas/core/ops/common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     79\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/myenv/lib/python3.8/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/myenv/lib/python3.8/site-packages/pandas/core/indexes/base.py:6761\u001b[0m, in \u001b[0;36mIndex._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6756\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m arr\n\u001b[1;32m   6758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, (np\u001b[38;5;241m.\u001b[39mndarray, Index, ABCSeries, ExtensionArray)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m   6759\u001b[0m     \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   6760\u001b[0m ) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(other):\n\u001b[0;32m-> 6761\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLengths must match to compare\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6763\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, ABCMultiIndex):\n\u001b[1;32m   6764\u001b[0m     other \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: Lengths must match to compare"
     ]
    }
   ],
   "source": [
    "y.index == X.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sktime.split import TemporalTrainTestSplitter\n",
    "\n",
    "splitter = TemporalTrainTestSplitter(test_size=0.2)\n",
    "\n",
    "# Perform the split and save the indices into train and test variables\n",
    "train_indices, test_indices = next(splitter.split(X.index.get_level_values(1)))\n",
    "X_train = X.iloc[train_indices]\n",
    "X_test = X.iloc[test_indices]\n",
    "train_indices_y, test_indices_y = next(splitter.split(y.index.get_level_values(1)))\n",
    "y_train = y.iloc[train_indices]\n",
    "y_test = y.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "splitter = TemporalTrainTestSplitter(test_size=0.3)\n",
    "train_indices, test_indices = next(splitter.split(X.index.get_level_values(1)))\n",
    "\n",
    "# Extract train and test data using iloc for positional indexing\n",
    "X_train = X.iloc[train_indices]\n",
    "X_test = X.iloc[test_indices]\n",
    "y_train = y.iloc[train_indices]\n",
    "y_test = y.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rocket classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocket = RocketClassifier()\n",
    "rocket.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = RocketClassifier()\n",
    "# model1.set_config(n_jobs=-1)\n",
    "model1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y, rocket.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "timeseries svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TimeSeriesSVC()\n",
    "# model.set_config('n_jobs'=-1)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y, model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.set_config({ \n",
    "#                   'backend:parallel': True,\n",
    "#  'backend:parallel:params': True\n",
    "#  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# data = {\n",
    "#     'Primary_Index': [0, 0, 1, 1],\n",
    "#     'ref_date': ['2016-08-17', '2016-09-02', '2017-07-16', '2017-10-25'],\n",
    "#     'ethnicity_mapping': [0.0, 0.0, 1.0, 1.0],\n",
    "#     'gender': [0.0, 0.0, 1.0, 1.0],\n",
    "#     'marital_status': [1.0, 1.0, 1.0, 1.0],\n",
    "#     # Add more features as needed\n",
    "# }\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "# df['ref_date'] = pd.to_datetime(df['ref_date'])\n",
    "# df.set_index(['Primary_Index', 'ref_date'], inplace=True)\n",
    "\n",
    "# # Group by Primary_Index\n",
    "# grouped = df.groupby(level=0)\n",
    "\n",
    "# # Create the nested DataFrame dynamically\n",
    "# nested_data = pd.DataFrame()\n",
    "\n",
    "# for col in df.columns:\n",
    "#     nested_data[col] = grouped[col].apply(list)\n",
    "\n",
    "# # Convert lists to numpy arrays for sktime compatibility\n",
    "# nested_data = nested_data.applymap(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_filtered.groupby(level=0)\n",
    "\n",
    "nested_data = pd.DataFrame()\n",
    "\n",
    "for col in df_filtered.columns:\n",
    "    if col=='is_diagnosed':\n",
    "        continue\n",
    "    try:\n",
    "        nested_data[col] = grouped[col].apply(list)\n",
    "    except:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "nested_data = copy.deepcopy(nested_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_data = nested_data.applymap(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert 'ref_date' index to datetime if it's not already\n",
    "if not pd.api.types.is_datetime64_any_dtype(df_filtered.index.get_level_values('ref_date')):\n",
    "    # Create a new MultiIndex with the 'ref_date' converted to datetime\n",
    "    df_filtered.index = pd.MultiIndex.from_arrays([\n",
    "        df_filtered.index.get_level_values('Primary_Index'),\n",
    "        pd.to_datetime(df_filtered.index.get_level_values('ref_date'))\n",
    "    ], names=['Primary_Index', 'ref_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_filtered.index.get_level_values('ref_date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reprint the index to check\n",
    "print(df_filtered.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datatypes import check_raise\n",
    "\n",
    "try:\n",
    "    check_raise(df_filtered, mtype=\"pd-multiindex\")\n",
    "    print(\"Data is in the correct format.\")\n",
    "except Exception as e:\n",
    "    print(f\"Data format error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datatypes import check_raise\n",
    "\n",
    "try:\n",
    "    check_raise(df_filtered, mtype=\"pd-multiindex\")\n",
    "    print(\"Data is in the correct format.\")\n",
    "except Exception as e:\n",
    "    print(f\"Data format error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "from sktime.classification.deep_learning import InceptionTimeClassifier\n",
    "from sktime.datasets import load_unit_test  \n",
    "X_train, y_train = load_unit_test(split=\"train\")  \n",
    "X_test, y_test = load_unit_test(split=\"test\")  \n",
    "clf = InceptionTimeClassifier()  \n",
    "clf.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_unit_test(split=\"train\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_filtered.drop(columns=['is_diagnosed', 'time_in_days'])\n",
    "target = df_filtered['is_diagnosed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sktime.classification.deep_learning import InceptionTimeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sktime.classification.kernel_based as something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert MultiIndex DataFrame to nested format expected by sktime\n",
    "X_nested = features.groupby(level=0).apply(lambda g: g.droplevel(0).reset_index(drop=True))\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_nested, target, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert MultiIndex DataFrame to the required format\n",
    "def convert_to_sktime_format(df):\n",
    "    grouped = df.groupby(level=0)\n",
    "    nested_list = [group.droplevel(0).reset_index(drop=True).T for _, group in grouped]\n",
    "    nested_df = pd.DataFrame(nested_list)\n",
    "    return nested_df\n",
    "\n",
    "# Convert the features DataFrame to the required format\n",
    "X_sktime = convert_to_sktime_format(features)\n",
    "\n",
    "# Ensure target is properly aligned\n",
    "y_sktime = target.groupby(level=0).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tuple(map(tuple, X_train.values))\n",
    "X_test = tuple(map(tuple, X_test.values))\n",
    "y_train = tuple(y_train.values)\n",
    "y_test = tuple(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and F1 score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # Use 'weighted' to handle multiclass classification\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sktime.utils.data_processing import from_2d_array_to_nested\n",
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming df_filtered is your DataFrame and you have a target column\n",
    "X = df_filtered.drop(columns=['is_diagnosed','time_in_days']) # Feature set\n",
    "y = df_filtered['is_diagnosed']  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_filtered, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_unit_test(split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[0].loc[9, 'dim_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the DataFrame is sorted by the index\n",
    "df_filtered = df_filtered.sort_index()\n",
    "\n",
    "# Convert MultiIndex DataFrame to the required format\n",
    "def convert_to_sktime_format(df):\n",
    "    grouped = df.groupby(level=0)\n",
    "    nested_list = [group.droplevel(0).reset_index(drop=True).T for _, group in grouped]\n",
    "    nested_df = pd.DataFrame(nested_list)\n",
    "    return nested_df\n",
    "\n",
    "# Convert the features DataFrame to the required format\n",
    "X_sktime = convert_to_sktime_format(df_filtered)\n",
    "\n",
    "# Ensure target is properly aligned\n",
    "y_sktime = y.groupby(level=0).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sktime.classification.deep_learning import InceptionTimeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "df = df_filtered\n",
    "# Assuming 'target' is the column name for your target variable\n",
    "target_column = 'is_diagnosed'  # Replace with your actual target column name\n",
    "\n",
    "# Check if 'time_in_days' needs to be dropped\n",
    "if 'time_in_days' in df.columns:\n",
    "    df = df.drop(columns=['time_in_days'])\n",
    "\n",
    "# Ensure the primary index is set correctly for both features and target\n",
    "df = df.set_index(['Primary_Index', 'ref_date'])\n",
    "target = df[target_column].groupby('Primary_Index').first()\n",
    "features = df.drop(columns=[target_column])\n",
    "\n",
    "# Convert MultiIndex DataFrame to nested format expected by sktime\n",
    "def convert_to_nested(df):\n",
    "    # Group by primary index and convert each group to a Series\n",
    "    nested_df = df.groupby(level=0).apply(lambda g: g.droplevel(0).reset_index(drop=True))\n",
    "    return nested_df\n",
    "\n",
    "# Assuming your DataFrame is already set with a MultiIndex\n",
    "X_nested = convert_to_nested(features)\n",
    "\n",
    "# Ensure target is properly aligned\n",
    "y_nested = target.groupby(level=0).first()\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_nested, y_nested, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the classifier\n",
    "clf = InceptionTimeClassifier()\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and F1 score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(f\"\\nAccuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = InceptionTimeClassifier()  \n",
    "clf.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data into a pandas DataFrame\n",
    "file_path = '/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/FeatureEngineering/Heart_I25/test1/diagnosed.csv'  # Replace with your file path\n",
    "filepath1 = '/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/FeatureEngineering/Heart_I25/test1/normal.csv'\n",
    "diagnosed_df = pd.read_csv(file_path)\n",
    "normal_df = pd.read_csv(filepath1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a unique identifier for each (PatientID, Practice) combination\n",
    "diagnosed_df['Primary_Index'] = diagnosed_df.groupby(['PatientID', 'Practice']).ngroup()\n",
    "diagnosed_df.set_index(['Primary_Index', 'ref_date'], inplace=True)\n",
    "# Sort the index for better readability\n",
    "diagnosed_df.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "# Create a unique identifier for each (PatientID, Practice) combination\n",
    "normal_df['Primary_Index'] = normal_df.groupby(['PatientID', 'Practice']).ngroup()\n",
    "normal_df.set_index(['Primary_Index', 'ref_date'], inplace=True)\n",
    "# Sort the index for better readability\n",
    "normal_df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_df.to_csv('normal_dataset.csv', index=True)\n",
    "diagnosed_df.to_csv('diagnosed_dataset.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/FeatureEngineering/diagnosed_dataset.csv', index_col=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_df = normal_df.drop(columns=['race', 'age', 'Practice'])\n",
    "diagnosed_df = diagnosed_df.drop(columns=['race', 'age', 'Practice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# # Split the DataFrame into two parts\n",
    "# df_diagnosed, df_normal = train_test_split(diagnosed_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# # Save each split DataFrame into separate CSV files\n",
    "# df_diagnosed.to_csv('fake_diagnosed.csv', index=True)\n",
    "# df_normal.to_csv('fake_normal.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "normal_df['threshold_date'] = pd.to_datetime(normal_df['threshold_date'])\n",
    "normal_df['latest_encounter'] = pd.to_datetime(normal_df['latest_encounter'])\n",
    "normal_df['date_of_birth'] = pd.to_datetime(normal_df['date_of_birth'])\n",
    "normal_df['date_of_death'] = pd.to_datetime(normal_df['date_of_death'])\n",
    "\n",
    "diagnosed_df['threshold_date'] = pd.to_datetime(diagnosed_df['threshold_date'])\n",
    "diagnosed_df['diagnosis_date'] = pd.to_datetime(diagnosed_df['diagnosis_date'])\n",
    "diagnosed_df['date_of_birth'] = pd.to_datetime(diagnosed_df['date_of_birth'])\n",
    "diagnosed_df['date_of_death'] = pd.to_datetime(diagnosed_df['date_of_death'], errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datatypes import check_raise\n",
    "\n",
    "# Check if the DataFrame is compatible with sktime\n",
    "try:\n",
    "    check_raise(normal_df, mtype=\"pd-multiindex\")\n",
    "    print(\"Data is in the correct format.\")\n",
    "except Exception as e:\n",
    "    print(f\"Data format error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datatypes import check_raise\n",
    "\n",
    "# Check if the DataFrame is compatible with sktime\n",
    "try:\n",
    "    check_raise(diagnosed_df, mtype=\"pd-multiindex\")\n",
    "    print(\"Data is in the correct format.\")\n",
    "except Exception as e:\n",
    "    print(f\"Data format error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = diagnosed_df.select_dtypes(include=['object']).columns\n",
    "object_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normal_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RocketClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sktime\n",
    "\n",
    "sktime.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.index.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Check the current type of the 'ref_date' index\n",
    "print(df_filtered.index.get_level_values('ref_date'))\n",
    "\n",
    "# Convert 'ref_date' index to datetime if it's not already\n",
    "if not pd.api.types.is_datetime64_any_dtype(df_filtered.index.get_level_values('ref_date')):\n",
    "    # Create a new MultiIndex with the 'ref_date' converted to datetime\n",
    "    df_filtered.index = pd.MultiIndex.from_arrays([\n",
    "        df_filtered.index.get_level_values('Primary_Index'),\n",
    "        pd.to_datetime(df_filtered.index.get_level_values('ref_date'))\n",
    "    ], names=['Primary_Index', 'ref_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reprint the index to check\n",
    "print(df_filtered.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datatypes import check_raise\n",
    "\n",
    "try:\n",
    "    check_raise(df_filtered, mtype=\"pd-multiindex\")\n",
    "    print(\"Data is in the correct format.\")\n",
    "except Exception as e:\n",
    "    print(f\"Data format error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates in the index\n",
    "if df_filtered.index.duplicated().any():\n",
    "    print(\"There are duplicate indices.\")\n",
    "    # Optional: Drop duplicates if necessary\n",
    "    df_filtered = df_filtered[~df_filtered.index.duplicated(keep='first')]\n",
    "else:\n",
    "    print(\"No duplicate indices found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sktime.utils.data_processing import from_2d_array_to_nested\n",
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming df_filtered is your DataFrame and you have a target column\n",
    "X = df_filtered.drop(columns=['is_diagnosed','time_in_days']) # Feature set\n",
    "y = df_filtered['is_diagnosed']  # Target variable\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RocketClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'X' is a DataFrame where each row is a time series\n",
    "# Create a nested DataFrame\n",
    "def convert_to_nested(df):\n",
    "    nested_data = {col: [pd.Series(df[col].iloc[i]) for i in range(df.shape[0])] for col in df.columns}\n",
    "    return pd.DataFrame(nested_data)\n",
    "\n",
    "X_nested = convert_to_nested(X)\n",
    "\n",
    "# Verify the structure\n",
    "print(X_nested.head())\n",
    "print(f\"Shape of X_nested: {X_nested.shape}\")\n",
    "print(f\"Length of y: {len(y)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set([x[0] for x in (X.index.to_list())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_nested.to_csv(\"x_nested.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_nested, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "# Initialize and train the RocketClassifier\n",
    "rocket_clf = RocketClassifier()\n",
    "rocket_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rocket_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for nested data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for pd.multiindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "\n",
    "# Initialize and train the RocketClassifier\n",
    "rocket_clf = RocketClassifier()\n",
    "rocket_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rocket_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for pd.wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sktime.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.utils.data_processing import from_2d_array_to_nested\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_nested = from_2d_array_to_nested(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datatypes import check_raise\n",
    "\n",
    "# Check if the DataFrame is compatible with sktime\n",
    "try:\n",
    "    check_raise(df_filtered, mtype=\"pd-multiindex\")\n",
    "    print(\"Data is in the correct format.\")\n",
    "except Exception as e:\n",
    "    print(f\"Data format error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "\n",
    "TemporalTrainTestSplitter(x, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = pd.read_csv(\"/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/X_train.csv\", index_col=[0,1])\n",
    "# y_train = pd.read_csv(\"/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/y_train.csv\", index_col=[0,1])\n",
    "\n",
    "# x_test = pd.read_csv(\"/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/X_test.csv\", index_col=[0,1])\n",
    "# y_test = pd.read_csv(\"/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/y_test.csv\", index_col=[0,1])\n",
    "\n",
    "# x_val = pd.read_csv(\"/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/x_val.csv\", index_col=[0,1])\n",
    "# y_val = pd.read_csv(\"/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/Modelling/y_val.csv\", index_col=[0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(x_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "from sktime.datasets import load_unit_test\n",
    "# X_train, y_train = load_unit_test(split=\"train\", return_X_y=True)\n",
    "# X_test, y_test = load_unit_test(split=\"test\", return_X_y=True) \n",
    "clf = RocketClassifier(num_kernels=500) \n",
    "clf.fit(x_train, y_train) \n",
    "y_pred = clf.predict(x_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_unit_test(return_X_y=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(load_unit_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(load_unit_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for simplest evaluation, compare ground truth to predictions\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import to retrieve examples\n",
    "from sktime.datatypes import get_examples\n",
    "get_examples(mtype=\"pd-multiindex\", as_scitype=\"Panel\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.datasets import load_osuleaf\n",
    "\n",
    "# data should be split into train/test\n",
    "X_train, y_train = load_osuleaf(split=\"train\", return_type=\"numpy3D\")\n",
    "X_test, y_test = load_osuleaf(split=\"test\", return_type=\"numpy3D\")\n",
    "X_test = X_test[:2]\n",
    "y_test = y_test[:2]\n",
    "\n",
    "# step 3-5 are the same\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.dists_kernels.compose_tab_to_panel import AggrDist\n",
    "from sktime.dists_kernels import ScipyDist\n",
    "\n",
    "mean_eucl_dist = AggrDist(ScipyDist())\n",
    "clf = KNeighborsTimeSeriesClassifier(n_neighbors=3, distance=mean_eucl_dist)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# for simplest evaluation, compare ground truth to predictions\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "from sktime.datasets import load_unit_test\n",
    "X_train, y_train = load_unit_test(split=\"train\", return_X_y=True)\n",
    "X_test, y_test = load_unit_test(split=\"test\", return_X_y=True) \n",
    "clf = RocketClassifier(num_kernels=500) \n",
    "clf.fit(X_train, y_train) \n",
    "y_pred = clf.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_unit_test(split='test', return_X_y=True, return_type=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for simplest evaluation, compare ground truth to predictions\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('/ext01/medgp1167/ushbahh/NEW_DISEASES/Chronic Disease Modelling/FeatureEngineering/Hyperlipidemia_E78/test_temporal1/diagnosed.csv')\n",
    "\n",
    "# Convert 'date' and 'ref_date' to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['ref_date'] = pd.to_datetime(df['ref_date'])\n",
    "\n",
    "# Sort the data\n",
    "df = df.sort_values(['PatientID', 'ref_date', 'date'])\n",
    "\n",
    "# Feature Scaling (excluding non-numeric columns)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df[df.columns.difference(['PatientID', 'date', 'ref_date', 'target_column'])] = scaler.fit_transform(df[df.columns.difference(['PatientID', 'date', 'ref_date', 'target_column'])])\n",
    "\n",
    "# Create sequences for each ref_date\n",
    "def create_sequences(df, seq_length=5):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for patient in df['PatientID'].unique():\n",
    "        patient_data = df[df['PatientID'] == patient]\n",
    "        for ref_date in patient_data['ref_date'].unique():\n",
    "            ref_data = patient_data[patient_data['ref_date'] == ref_date]\n",
    "            for i in range(len(ref_data) - seq_length + 1):\n",
    "                sequence = ref_data.iloc[i:i + seq_length].drop(['PatientID', 'ref_date', 'target_column'], axis=1).values\n",
    "                target = ref_data['target_column'].values[i + seq_length - 1]\n",
    "                sequences.append(sequence)\n",
    "                targets.append(target)\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "seq_length = 5\n",
    "X, y = create_sequences(df, seq_length)\n",
    "\n",
    "# Train-Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# LSTM Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seq_length, X_train.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
